# 测试环境配置
## 数据库配置
spark.local=true
jdbc.url=jdbc:mysql://192.168.20.60:3306/xiaopeng2_bi?user=xiaopeng&password=xiaopeng99&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false
jdbc.user=xiaopeng
jdbc.pwd=xiaopeng99
jdbc.xiaopeng2.url=jdbc:mysql://192.168.20.60:3306/xiaopeng2?user=xiaopeng&password=xiaopeng99&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false
jdbc.xiaopeng2bihip.url=jdbc:mysql://192.168.20.60:3306/xiaopeng2_bi?user=xiaopeng&password=xiaopeng99&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false
jdbc.xiaopeng2fx.url=jdbc:mysql://192.168.20.60:3306/xiaopeng2_faxing?user=xiaopeng&password=xiaopeng99&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false
jdbc.driver=com.mysql.jdbc.Driver


# kafka 配置
kafka.metadata.broker.list=master-yyft:9092,slaves01-yyft:9092,slaves02-yyft:9092

kafka.topics.login=login
spark.checkpoint.login=/home/hduser/spark/spark-1.6.1/checkpointdir/login

kafka.topics.account=login,regi,order
spark.checkpoint.account=/home/hduser/spark/spark-1.6.1/checkpointdir/centurioncardaccount

kafka.topics.apppoints=order,points
spark.checkpoint.apppoints=/home/hduser/spark/spark-1.6.1/checkpointdir/apppoints

kafka.topics.basekpi=channel,active,order,regi,request,pubgame
spark.checkpoint.basekpi=/home/hduser/spark/spark-1.6.1/checkpointdir/basekpi

kafka.topics.kpi=regi,order,login,active,pubgame
spark.checkpoint.kpi=/home/hduser/spark/spark-1.6.1/checkpointdir/kpi_regi

kafka.topics.everylogin=login
spark.checkpoint.everylogin=/home/hduser/spark/spark-1.6.1/checkpointdir/appeverylogin

kafka.topics.click=channel,request,pubgame

kafka.topics.payclick=order,pubgame


#离线任务 数据目录配置
gamepublish.offline.regi=hdfs://master-yyft:9000/user/hive/warehouse/yyft.db/regi/*
gamepublish.offline.order=hdfs://master-yyft:9000/user/hive/warehouse/yyft.db/order/*
gamepublish.offline.pubgame=hdfs://master-yyft:9000/user/hive/warehouse/yyft.db/pubgame/*

fxdim.parquet=hdfs://master-yyft:9000/tmp/hive/fxdim.parquet

# spark 参数配置
coalesce.partitioin.num=40
spark.sql.shuffle.partitions=40
spark.memory.storageFraction=0.2

#redis相关配置
redis.host=192.168.20.177
redis.port=6379
redis.max.idle=50
redis.max.total=1000
redis.max.wait.millis=10000

#web交互的模式
web.url.mode=test

